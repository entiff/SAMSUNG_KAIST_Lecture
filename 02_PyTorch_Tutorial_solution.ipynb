{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![nn](img/pytorch_02.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실습 목표"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Neural network 모델을 만들고 학습시킬 수 있다.\n",
    "- 모델을 튜닝하여 원하는 성능을 얻을 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpu number 지정\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'  # 1차 과정 gpu number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![nn](img/pytorch_08.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST dataset \n",
    "train_dataset = torchvision.datasets.MNIST(root='datasets/', train=True, transform=transforms.ToTensor(), download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='datasets/', train=False, transform=transforms.ToTensor())\n",
    "\n",
    "# Data loader\n",
    "# mini batch size\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![nn](img/pytorch_07.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 class 선언\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size) \n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, output_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.sigmoid(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.sigmoid(out)\n",
    "        out = self.fc3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 instance 생성\n",
    "model = NeuralNet(784, 20, 10)  # init(784, 20, 10)\n",
    "# input dim: 784  / hidden dim: 20  / output dim: 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNet(\n",
       "  (fc1): Linear(in_features=784, out_features=20, bias=True)\n",
       "  (fc2): Linear(in_features=20, out_features=20, bias=True)\n",
       "  (fc3): Linear(in_features=20, out_features=10, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpu 사용\n",
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 잘 학습이 되었는지 판단 기준\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.05) \n",
    "# torch.optim.SGD(model.parameters(), lr=0.05, momentum=0.9)\n",
    "# torch.optim.Adam(model.parameters(), lr=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![nn](img/pytorch_09.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [100/469], Loss: 2.2968\n",
      "Epoch [1/10], Step [200/469], Loss: 2.2902\n",
      "Epoch [1/10], Step [300/469], Loss: 2.2916\n",
      "Epoch [1/10], Step [400/469], Loss: 2.2966\n",
      "Epoch [2/10], Step [100/469], Loss: 2.2727\n",
      "Epoch [2/10], Step [200/469], Loss: 2.2706\n",
      "Epoch [2/10], Step [300/469], Loss: 2.2578\n",
      "Epoch [2/10], Step [400/469], Loss: 2.2406\n",
      "Epoch [3/10], Step [100/469], Loss: 2.1911\n",
      "Epoch [3/10], Step [200/469], Loss: 2.1588\n",
      "Epoch [3/10], Step [300/469], Loss: 2.0711\n",
      "Epoch [3/10], Step [400/469], Loss: 2.0070\n",
      "Epoch [4/10], Step [100/469], Loss: 1.8577\n",
      "Epoch [4/10], Step [200/469], Loss: 1.7323\n",
      "Epoch [4/10], Step [300/469], Loss: 1.6590\n",
      "Epoch [4/10], Step [400/469], Loss: 1.4602\n",
      "Epoch [5/10], Step [100/469], Loss: 1.4875\n",
      "Epoch [5/10], Step [200/469], Loss: 1.4059\n",
      "Epoch [5/10], Step [300/469], Loss: 1.2327\n",
      "Epoch [5/10], Step [400/469], Loss: 1.1442\n",
      "Epoch [6/10], Step [100/469], Loss: 1.0709\n",
      "Epoch [6/10], Step [200/469], Loss: 1.0047\n",
      "Epoch [6/10], Step [300/469], Loss: 1.0573\n",
      "Epoch [6/10], Step [400/469], Loss: 1.0901\n",
      "Epoch [7/10], Step [100/469], Loss: 0.9763\n",
      "Epoch [7/10], Step [200/469], Loss: 0.9593\n",
      "Epoch [7/10], Step [300/469], Loss: 0.8801\n",
      "Epoch [7/10], Step [400/469], Loss: 0.8338\n",
      "Epoch [8/10], Step [100/469], Loss: 0.8786\n",
      "Epoch [8/10], Step [200/469], Loss: 0.8694\n",
      "Epoch [8/10], Step [300/469], Loss: 0.8926\n",
      "Epoch [8/10], Step [400/469], Loss: 0.8875\n",
      "Epoch [9/10], Step [100/469], Loss: 0.7191\n",
      "Epoch [9/10], Step [200/469], Loss: 0.6434\n",
      "Epoch [9/10], Step [300/469], Loss: 0.6887\n",
      "Epoch [9/10], Step [400/469], Loss: 0.6751\n",
      "Epoch [10/10], Step [100/469], Loss: 0.6905\n",
      "Epoch [10/10], Step [200/469], Loss: 0.6621\n",
      "Epoch [10/10], Step [300/469], Loss: 0.6818\n",
      "Epoch [10/10], Step [400/469], Loss: 0.6602\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "total_step = len(train_loader)\n",
    "\n",
    "for epoch in range(10):\n",
    "    for i, (images, labels) in enumerate(train_loader):  # mini batch for loop\n",
    "        # gpu\n",
    "        images = images.reshape(-1, 28*28).to('cuda')\n",
    "        labels = labels.to('cuda')\n",
    "        \n",
    "        # Forward\n",
    "        outputs = model(images)  # forwardI(images)\n",
    "        loss = loss_fn(outputs, labels)  # 예측 값, 실제 값\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()  # 자동 미분값 계산\n",
    "        optimizer.step()  # requires_grad=True parameter 업데이트\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, 10, i+1, total_step, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 83.44 %\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, 28*28).to('cuda')\n",
    "        labels = labels.to('cuda')\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)  # classificatoin model -> top 1 label이 예측 값\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 퀴즈"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 아래 코드를 변형하여, Fully connected neural network의 MNIST classification  test 성능을  95% 이상으로 올려보세요.  정답은 물론 하나가 아니며, 코드의 변형이 많을수도 있고 적을수도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST dataset \n",
    "train_dataset = torchvision.datasets.MNIST(root='datasets/', train=True, transform=transforms.ToTensor(), download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='datasets/', train=False, transform=transforms.ToTensor())\n",
    "\n",
    "# Data loader\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size) \n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc4 = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = F.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.fc3(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.fc4(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNet(784, 50, 10)\n",
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1], Step [100/1875], Loss: 0.2540\n",
      "Epoch [1], Step [200/1875], Loss: 0.3388\n",
      "Epoch [1], Step [300/1875], Loss: 0.2909\n",
      "Epoch [1], Step [400/1875], Loss: 0.3307\n",
      "Epoch [1], Step [500/1875], Loss: 0.3641\n",
      "Epoch [1], Step [600/1875], Loss: 0.3738\n",
      "Epoch [1], Step [700/1875], Loss: 0.2374\n",
      "Epoch [1], Step [800/1875], Loss: 0.3779\n",
      "Epoch [1], Step [900/1875], Loss: 0.1987\n",
      "Epoch [1], Step [1000/1875], Loss: 0.2675\n",
      "Epoch [1], Step [1100/1875], Loss: 0.2308\n",
      "Epoch [1], Step [1200/1875], Loss: 0.0732\n",
      "Epoch [1], Step [1300/1875], Loss: 0.0305\n",
      "Epoch [1], Step [1400/1875], Loss: 0.0852\n",
      "Epoch [1], Step [1500/1875], Loss: 0.1668\n",
      "Epoch [1], Step [1600/1875], Loss: 0.2521\n",
      "Epoch [1], Step [1700/1875], Loss: 0.1314\n",
      "Epoch [1], Step [1800/1875], Loss: 0.1734\n",
      "Epoch [2], Step [100/1875], Loss: 0.0724\n",
      "Epoch [2], Step [200/1875], Loss: 0.1043\n",
      "Epoch [2], Step [300/1875], Loss: 0.0577\n",
      "Epoch [2], Step [400/1875], Loss: 0.0516\n",
      "Epoch [2], Step [500/1875], Loss: 0.2164\n",
      "Epoch [2], Step [600/1875], Loss: 0.2721\n",
      "Epoch [2], Step [700/1875], Loss: 0.2749\n",
      "Epoch [2], Step [800/1875], Loss: 0.1035\n",
      "Epoch [2], Step [900/1875], Loss: 0.0775\n",
      "Epoch [2], Step [1000/1875], Loss: 0.2046\n",
      "Epoch [2], Step [1100/1875], Loss: 0.1405\n",
      "Epoch [2], Step [1200/1875], Loss: 0.0961\n",
      "Epoch [2], Step [1300/1875], Loss: 0.1796\n",
      "Epoch [2], Step [1400/1875], Loss: 0.0446\n",
      "Epoch [2], Step [1500/1875], Loss: 0.2849\n",
      "Epoch [2], Step [1600/1875], Loss: 0.2637\n",
      "Epoch [2], Step [1700/1875], Loss: 0.0197\n",
      "Epoch [2], Step [1800/1875], Loss: 0.6166\n",
      "Epoch [3], Step [100/1875], Loss: 0.1038\n",
      "Epoch [3], Step [200/1875], Loss: 0.1122\n",
      "Epoch [3], Step [300/1875], Loss: 0.0883\n",
      "Epoch [3], Step [400/1875], Loss: 0.1227\n",
      "Epoch [3], Step [500/1875], Loss: 0.2026\n",
      "Epoch [3], Step [600/1875], Loss: 0.3448\n",
      "Epoch [3], Step [700/1875], Loss: 0.0651\n",
      "Epoch [3], Step [800/1875], Loss: 0.0109\n",
      "Epoch [3], Step [900/1875], Loss: 0.0659\n",
      "Epoch [3], Step [1000/1875], Loss: 0.2861\n",
      "Epoch [3], Step [1100/1875], Loss: 0.0238\n",
      "Epoch [3], Step [1200/1875], Loss: 0.0652\n",
      "Epoch [3], Step [1300/1875], Loss: 0.3012\n",
      "Epoch [3], Step [1400/1875], Loss: 0.0126\n",
      "Epoch [3], Step [1500/1875], Loss: 0.0035\n",
      "Epoch [3], Step [1600/1875], Loss: 0.0811\n",
      "Epoch [3], Step [1700/1875], Loss: 0.2423\n",
      "Epoch [3], Step [1800/1875], Loss: 0.0584\n",
      "Epoch [4], Step [100/1875], Loss: 0.2463\n",
      "Epoch [4], Step [200/1875], Loss: 0.0722\n",
      "Epoch [4], Step [300/1875], Loss: 0.0201\n",
      "Epoch [4], Step [400/1875], Loss: 0.0283\n",
      "Epoch [4], Step [500/1875], Loss: 0.1561\n",
      "Epoch [4], Step [600/1875], Loss: 0.0092\n",
      "Epoch [4], Step [700/1875], Loss: 0.0369\n",
      "Epoch [4], Step [800/1875], Loss: 0.0416\n",
      "Epoch [4], Step [900/1875], Loss: 0.1040\n",
      "Epoch [4], Step [1000/1875], Loss: 0.0257\n",
      "Epoch [4], Step [1100/1875], Loss: 0.1147\n",
      "Epoch [4], Step [1200/1875], Loss: 0.1342\n",
      "Epoch [4], Step [1300/1875], Loss: 0.2278\n",
      "Epoch [4], Step [1400/1875], Loss: 0.2335\n",
      "Epoch [4], Step [1500/1875], Loss: 0.0345\n",
      "Epoch [4], Step [1600/1875], Loss: 0.0257\n",
      "Epoch [4], Step [1700/1875], Loss: 0.1694\n",
      "Epoch [4], Step [1800/1875], Loss: 0.0190\n",
      "Epoch [5], Step [100/1875], Loss: 0.1694\n",
      "Epoch [5], Step [200/1875], Loss: 0.0028\n",
      "Epoch [5], Step [300/1875], Loss: 0.0261\n",
      "Epoch [5], Step [400/1875], Loss: 0.0640\n",
      "Epoch [5], Step [500/1875], Loss: 0.0377\n",
      "Epoch [5], Step [600/1875], Loss: 0.1415\n",
      "Epoch [5], Step [700/1875], Loss: 0.0153\n",
      "Epoch [5], Step [800/1875], Loss: 0.1003\n",
      "Epoch [5], Step [900/1875], Loss: 0.0072\n",
      "Epoch [5], Step [1000/1875], Loss: 0.0524\n",
      "Epoch [5], Step [1100/1875], Loss: 0.0269\n",
      "Epoch [5], Step [1200/1875], Loss: 0.1624\n",
      "Epoch [5], Step [1300/1875], Loss: 0.1315\n",
      "Epoch [5], Step [1400/1875], Loss: 0.0086\n",
      "Epoch [5], Step [1500/1875], Loss: 0.0435\n",
      "Epoch [5], Step [1600/1875], Loss: 0.2020\n",
      "Epoch [5], Step [1700/1875], Loss: 0.0441\n",
      "Epoch [5], Step [1800/1875], Loss: 0.0056\n",
      "Epoch [6], Step [100/1875], Loss: 0.0989\n",
      "Epoch [6], Step [200/1875], Loss: 0.1957\n",
      "Epoch [6], Step [300/1875], Loss: 0.0262\n",
      "Epoch [6], Step [400/1875], Loss: 0.1248\n",
      "Epoch [6], Step [500/1875], Loss: 0.0174\n",
      "Epoch [6], Step [600/1875], Loss: 0.0106\n",
      "Epoch [6], Step [700/1875], Loss: 0.0097\n",
      "Epoch [6], Step [800/1875], Loss: 0.1767\n",
      "Epoch [6], Step [900/1875], Loss: 0.1127\n",
      "Epoch [6], Step [1000/1875], Loss: 0.0742\n",
      "Epoch [6], Step [1100/1875], Loss: 0.0272\n",
      "Epoch [6], Step [1200/1875], Loss: 0.2506\n",
      "Epoch [6], Step [1300/1875], Loss: 0.0714\n",
      "Epoch [6], Step [1400/1875], Loss: 0.0815\n",
      "Epoch [6], Step [1500/1875], Loss: 0.0776\n",
      "Epoch [6], Step [1600/1875], Loss: 0.1260\n",
      "Epoch [6], Step [1700/1875], Loss: 0.1674\n",
      "Epoch [6], Step [1800/1875], Loss: 0.0024\n",
      "Epoch [7], Step [100/1875], Loss: 0.0182\n",
      "Epoch [7], Step [200/1875], Loss: 0.0121\n",
      "Epoch [7], Step [300/1875], Loss: 0.0626\n",
      "Epoch [7], Step [400/1875], Loss: 0.2028\n",
      "Epoch [7], Step [500/1875], Loss: 0.0882\n",
      "Epoch [7], Step [600/1875], Loss: 0.0433\n",
      "Epoch [7], Step [700/1875], Loss: 0.0828\n",
      "Epoch [7], Step [800/1875], Loss: 0.0211\n",
      "Epoch [7], Step [900/1875], Loss: 0.0351\n",
      "Epoch [7], Step [1000/1875], Loss: 0.1157\n",
      "Epoch [7], Step [1100/1875], Loss: 0.0250\n",
      "Epoch [7], Step [1200/1875], Loss: 0.0073\n",
      "Epoch [7], Step [1300/1875], Loss: 0.0423\n",
      "Epoch [7], Step [1400/1875], Loss: 0.0298\n",
      "Epoch [7], Step [1500/1875], Loss: 0.2396\n",
      "Epoch [7], Step [1600/1875], Loss: 0.0775\n",
      "Epoch [7], Step [1700/1875], Loss: 0.0084\n",
      "Epoch [7], Step [1800/1875], Loss: 0.1167\n",
      "Epoch [8], Step [100/1875], Loss: 0.0822\n",
      "Epoch [8], Step [200/1875], Loss: 0.0841\n",
      "Epoch [8], Step [300/1875], Loss: 0.0342\n",
      "Epoch [8], Step [400/1875], Loss: 0.2131\n",
      "Epoch [8], Step [500/1875], Loss: 0.0920\n",
      "Epoch [8], Step [600/1875], Loss: 0.2535\n",
      "Epoch [8], Step [700/1875], Loss: 0.2216\n",
      "Epoch [8], Step [800/1875], Loss: 0.0886\n",
      "Epoch [8], Step [900/1875], Loss: 0.1154\n",
      "Epoch [8], Step [1000/1875], Loss: 0.0043\n",
      "Epoch [8], Step [1100/1875], Loss: 0.1266\n",
      "Epoch [8], Step [1200/1875], Loss: 0.0504\n",
      "Epoch [8], Step [1300/1875], Loss: 0.0077\n",
      "Epoch [8], Step [1400/1875], Loss: 0.1702\n",
      "Epoch [8], Step [1500/1875], Loss: 0.0108\n",
      "Epoch [8], Step [1600/1875], Loss: 0.1002\n",
      "Epoch [8], Step [1700/1875], Loss: 0.0148\n",
      "Epoch [8], Step [1800/1875], Loss: 0.1464\n",
      "Epoch [9], Step [100/1875], Loss: 0.0431\n",
      "Epoch [9], Step [200/1875], Loss: 0.0218\n",
      "Epoch [9], Step [300/1875], Loss: 0.0545\n",
      "Epoch [9], Step [400/1875], Loss: 0.0548\n",
      "Epoch [9], Step [500/1875], Loss: 0.0059\n",
      "Epoch [9], Step [600/1875], Loss: 0.0108\n",
      "Epoch [9], Step [700/1875], Loss: 0.0146\n",
      "Epoch [9], Step [800/1875], Loss: 0.1167\n",
      "Epoch [9], Step [900/1875], Loss: 0.1455\n",
      "Epoch [9], Step [1000/1875], Loss: 0.0507\n",
      "Epoch [9], Step [1100/1875], Loss: 0.0580\n",
      "Epoch [9], Step [1200/1875], Loss: 0.0382\n",
      "Epoch [9], Step [1300/1875], Loss: 0.0179\n",
      "Epoch [9], Step [1400/1875], Loss: 0.0514\n",
      "Epoch [9], Step [1500/1875], Loss: 0.0228\n",
      "Epoch [9], Step [1600/1875], Loss: 0.0500\n",
      "Epoch [9], Step [1700/1875], Loss: 0.0321\n",
      "Epoch [9], Step [1800/1875], Loss: 0.0893\n",
      "Epoch [10], Step [100/1875], Loss: 0.0197\n",
      "Epoch [10], Step [200/1875], Loss: 0.0481\n",
      "Epoch [10], Step [300/1875], Loss: 0.1835\n",
      "Epoch [10], Step [400/1875], Loss: 0.3462\n",
      "Epoch [10], Step [500/1875], Loss: 0.0886\n",
      "Epoch [10], Step [600/1875], Loss: 0.0027\n",
      "Epoch [10], Step [700/1875], Loss: 0.0292\n",
      "Epoch [10], Step [800/1875], Loss: 0.0100\n",
      "Epoch [10], Step [900/1875], Loss: 0.1953\n",
      "Epoch [10], Step [1000/1875], Loss: 0.0105\n",
      "Epoch [10], Step [1100/1875], Loss: 0.1715\n",
      "Epoch [10], Step [1200/1875], Loss: 0.1476\n",
      "Epoch [10], Step [1300/1875], Loss: 0.0035\n",
      "Epoch [10], Step [1400/1875], Loss: 0.0118\n",
      "Epoch [10], Step [1500/1875], Loss: 0.0034\n",
      "Epoch [10], Step [1600/1875], Loss: 0.0446\n",
      "Epoch [10], Step [1700/1875], Loss: 0.0745\n",
      "Epoch [10], Step [1800/1875], Loss: 0.0197\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(10):\n",
    "    for i, (images, labels) in enumerate(train_loader):  \n",
    "        # Move tensors to the configured device\n",
    "        images = images.reshape(-1, 28*28).to('cuda')\n",
    "        labels = labels.to('cuda')\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch [{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, i+1, total_step, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 96.94 %\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, 28*28).to('cuda')\n",
    "        labels = labels.to('cuda')\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 생각해보기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 이전 퀴즈에서 사용한 방법 외에 어떤 시도를 더 해볼 수 있을까요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
